#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å®é™…å­—å¹•ç”Ÿæˆæ•ˆæœ - æ¨¡æ‹ŸåŒ…å«è‹±æ–‡å†…å®¹çš„å¡ç‰‡
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import json
from pathlib import Path

def create_test_card_with_english():
    """åˆ›å»ºåŒ…å«è‹±æ–‡å†…å®¹çš„æµ‹è¯•å¡ç‰‡"""
    print("ğŸ“ åˆ›å»ºåŒ…å«è‹±æ–‡å†…å®¹çš„æµ‹è¯•å¡ç‰‡")
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•
    test_dir = Path("/tmp/test_english_subtitle")
    test_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºåŒ…å«ä¸­è‹±æ–‡æ··åˆå†…å®¹çš„æµ‹è¯•å¡ç‰‡
    card_data = {
        "arXivID": "test.english.v1",
        "info_CN": [
            "2025å¹´8æœˆ21æ—¥arXiv,cs.CV,å‘æ–‡é‡çº¦97ç¯‡",
            "The Tsinghua University and Beijing Academy of Artificial Intelligence presented a unified representation that jointly models geometry and motion",
            "è¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œachieving state-of-the-art results on multiple benchmarks with impressive performance improvements",
            "This paper introduces a novel approach for machine learning applications in computer vision and natural language processing domains",
            "å‡è®ºAgenté€šè¿‡ç®—æ³•ä¸ºæ‚¨æ¨èä¼˜è´¨è®ºæ–‡å†…å®¹",
            "The proposed method demonstrates superior performance compared to existing approaches while maintaining computational efficiency"
        ],
        "info_EN": [
            "2025 arXiv cs.CV papers",
            "Tsinghua University research",
            "Performance improvements achieved",
            "Novel ML approach introduced", 
            "Agent recommendations",
            "Superior performance demonstrated"
        ]
    }
    
    # ä¿å­˜æµ‹è¯•å¡ç‰‡
    card_file = test_dir / "test_english.json"
    with open(card_file, 'w', encoding='utf-8') as f:
        json.dump(card_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æµ‹è¯•å¡ç‰‡å·²ä¿å­˜åˆ°: {card_file}")
    
    print("\nğŸ“‹ å¡ç‰‡å†…å®¹é¢„è§ˆ:")
    print("ä¸­æ–‡å¥å­ï¼ˆåŒ…å«è‹±æ–‡ï¼‰:")
    for i, sentence in enumerate(card_data["info_CN"], 1):
        print(f"  {i}. {sentence}")
        print(f"     é•¿åº¦: {len(sentence)} å­—ç¬¦")
    
    return str(card_file)

def test_subtitle_processing(card_file):
    """æµ‹è¯•å­—å¹•å¤„ç†æ•ˆæœ"""
    print(f"\nğŸ¬ æµ‹è¯•å­—å¹•å¤„ç†æ•ˆæœ")
    
    # åŠ è½½å¡ç‰‡æ•°æ®
    with open(card_file, 'r', encoding='utf-8') as f:
        card_data = json.load(f)
    
    # æ¨¡æ‹ŸVideoComposerçš„å¤„ç†
    from core.video_composer import VideoComposer
    composer = VideoComposer()
    
    sentences = card_data["info_CN"]
    print(f"\nå¤„ç† {len(sentences)} ä¸ªå¥å­çš„å­—å¹•:")
    print("="*80)
    
    for i, sentence in enumerate(sentences, 1):
        print(f"\nå¥å­ {i}: {sentence}")
        print(f"åŸå§‹é•¿åº¦: {len(sentence)} å­—ç¬¦")
        
        # æ£€æµ‹æ–‡æœ¬ç±»å‹
        is_english = composer._is_mainly_english(sentence)
        print(f"è¯†åˆ«ä¸º: {'ä¸»è¦è‹±æ–‡' if is_english else 'ä¸»è¦ä¸­æ–‡/æ··åˆ'}")
        
        # åº”ç”¨æ¢è¡Œ
        formatted_sentence = composer._devideSentence(sentence)
        lines = formatted_sentence.split('\n')
        
        print(f"æ¢è¡Œå: {len(lines)} è¡Œ")
        for j, line in enumerate(lines, 1):
            print(f"  è¡Œ{j}: {line}")
        
        # æ£€æŸ¥è‹±æ–‡æ˜¯å¦ç¬¦åˆè¦æ±‚
        if is_english:
            if len(lines) <= 2:
                print("âœ… è‹±æ–‡å­—å¹•ç¬¦åˆæœ€å¤š2è¡Œçš„è¦æ±‚")
            else:
                print("âŒ è‹±æ–‡å­—å¹•è¶…è¿‡2è¡Œï¼")
        
        print("-" * 60)

if __name__ == "__main__":
    print("ğŸ§ª å¼€å§‹è‹±æ–‡å­—å¹•æ¢è¡Œæµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•å¡ç‰‡
    card_file = create_test_card_with_english()
    
    # æµ‹è¯•å­—å¹•å¤„ç†
    test_subtitle_processing(card_file)
    
    print("\nğŸ¯ æµ‹è¯•å®Œæˆï¼")
    print("æ€»ç»“:")
    print("- è‹±æ–‡å¥å­ç°åœ¨æœ€å¤šæ˜¾ç¤º2è¡Œ")
    print("- ä¸­æ–‡å¥å­ä¿æŒåŸæœ‰çš„16å­—ç¬¦æ¢è¡Œ")
    print("- æ··åˆè¯­è¨€æ ¹æ®è‹±æ–‡å æ¯”è‡ªåŠ¨é€‰æ‹©å¤„ç†æ–¹å¼")
